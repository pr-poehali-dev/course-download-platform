"""
Business: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–º–∏ (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ, –ø–æ–ª—É—á–µ–Ω–∏–µ, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –∏–º–ø–æ—Ä—Ç —Å –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞)
Args: event —Å httpMethod, body, queryStringParameters
Returns: HTTP response —Å –¥–∞–Ω–Ω—ã–º–∏ —Ä–∞–±–æ—Ç
"""

import json
import os
import psycopg2
import requests
import re
from typing import Dict, Any, List, Optional
from docx import Document
from openai import OpenAI
from io import BytesIO
from PIL import Image

DATABASE_URL = os.environ.get('DATABASE_URL', '')
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')

def get_db_connection():
    return psycopg2.connect(DATABASE_URL)

def get_yandex_disk_folders(public_key: str) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ —Å –ø—Ä—è–º—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è"""
    url = 'https://cloud-api.yandex.net/v1/disk/public/resources'
    params = {'public_key': public_key, 'limit': 1000}
    
    print(f"üîç –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –ø–∞–ø–æ–∫ –∏–∑ –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞: {public_key}")
    response = requests.get(url, params=params)
    data = response.json()
    
    folders = []
    if '_embedded' in data and 'items' in data['_embedded']:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ—Ä–Ω–µ: {len(data['_embedded']['items'])}")
        for item in data['_embedded']['items']:
            if item['type'] == 'dir':
                folder_name = item['name']
                folder_public_url = item.get('public_url', '')
                print(f"üìÅ –î–æ–±–∞–≤–ª—è—é –ø–∞–ø–∫—É: {folder_name}")
                
                folders.append({
                    'name': folder_name,
                    'public_url': folder_public_url
                })
    
    print(f"üìä –ò—Ç–æ–≥–æ –ø–∞–ø–æ–∫ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞: {len(folders)}")
    return folders

def get_files_in_folder(public_key: str, folder_path: str) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞–ø–∫–∏ –ø–æ –ø—É—Ç–∏"""
    url = 'https://cloud-api.yandex.net/v1/disk/public/resources'
    params = {'public_key': public_key, 'path': folder_path, 'limit': 1000}
    
    response = requests.get(url, params=params)
    data = response.json()
    
    files = []
    if '_embedded' in data and 'items' in data['_embedded']:
        for item in data['_embedded']['items']:
            if item['type'] == 'file':
                file_path = item['path']
                download_url_endpoint = f"https://cloud-api.yandex.net/v1/disk/public/resources/download?public_key={public_key}&path={file_path}"
                
                try:
                    dl_response = requests.get(download_url_endpoint)
                    dl_data = dl_response.json()
                    file_url = dl_data.get('href', '')
                    
                    if file_url:
                        files.append({
                            'name': item['name'],
                            'download_url': file_url,
                            'mime_type': item.get('mime_type', ''),
                            'size': item.get('size', 0)
                        })
                except Exception as e:
                    pass
    
    return files

def parse_work_title_and_type(folder_name: str) -> Dict[str, str]:
    """–ò–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ç–∏–ø —Ä–∞–±–æ—Ç—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏"""
    work_type_map = {
        '–∫—É—Ä—Å–æ–≤–∞—è': '–∫—É—Ä—Å–æ–≤–∞—è',
        '–¥–∏–ø–ª–æ–º': '–¥–∏–ø–ª–æ–º',
        '—Ä–µ—Ñ–µ—Ä–∞—Ç': '—Ä–µ—Ñ–µ—Ä–∞—Ç',
        '—á–µ—Ä—Ç–µ–∂': '—á–µ—Ä—Ç–µ–∂',
        '–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è': '–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è',
        '–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è': '–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è'
    }
    
    match = re.search(r'\(([^)]+)\)', folder_name)
    work_type = '–¥—Ä—É–≥–æ–µ'
    
    if match:
        type_text = match.group(1).lower()
        for key, value in work_type_map.items():
            if key in type_text:
                work_type = value
                break
        title = folder_name.replace(match.group(0), '').strip()
    else:
        title = folder_name
    
    return {'title': title, 'work_type': work_type}

def download_file(url: str) -> bytes:
    """–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –ø–æ URL"""
    response = requests.get(url)
    return response.content

def extract_text_from_docx(content: bytes) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ DOCX —Ñ–∞–π–ª–∞"""
    doc = Document(BytesIO(content))
    text = '\n'.join([para.text for para in doc.paragraphs if para.text.strip()])
    return text

def generate_description_from_text(text: str, title: str, work_type: str) -> Dict[str, Any]:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —á–µ—Ä–µ–∑ OpenAI"""
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫—É—é —Ä–∞–±–æ—Ç—É –∏ –≤–µ—Ä–Ω–∏ JSON:
{{
  "subject": "–ø—Ä–µ–¥–º–µ—Ç —Ä–∞–±–æ—Ç—ã (—Ñ–∏–∑–∏–∫–∞, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ç.–¥.)",
  "description": "–æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ —á–µ–º —Ä–∞–±–æ—Ç–∞",
  "composition": "—Å–æ—Å—Ç–∞–≤ —Ä–∞–±–æ—Ç—ã (–≤–≤–µ–¥–µ–Ω–∏–µ, –≥–ª–∞–≤—ã, –∑–∞–∫–ª—é—á–µ–Ω–∏–µ, —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ —Ç.–¥.)",
  "price_points": —á–∏—Å–ª–æ –æ—Ç 50 –¥–æ 800 (–±–∞–ª–ª—ã –∑–∞ —Ä–∞–±–æ—Ç—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏)
}}

–ù–∞–∑–≤–∞–Ω–∏–µ: {title}
–¢–∏–ø —Ä–∞–±–æ—Ç—ã: {work_type}
–¢–µ–∫—Å—Ç —Ä–∞–±–æ—Ç—ã (–Ω–∞—á–∞–ª–æ): {text[:3000]}
"""
    
    response = client.chat.completions.create(
        model='gpt-4o-mini',
        messages=[{'role': 'user', 'content': prompt}],
        temperature=0.7,
        response_format={"type": "json_object"}
    )
    
    result = json.loads(response.choices[0].message.content)
    return result

def save_file_to_storage(content: bytes, filename: str) -> str:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª (–∑–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ S3)"""
    return f'https://storage.example.com/works/{filename}'

def handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    method: str = event.get('httpMethod', 'GET')
    
    if method == 'OPTIONS':
        return {
            'statusCode': 200,
            'headers': {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type, X-Admin-Email',
                'Access-Control-Max-Age': '86400'
            },
            'body': ''
        }
    
    if method == 'GET':
        query_params = event.get('queryStringParameters') or {}
        work_id = query_params.get('id')
        
        conn = get_db_connection()
        cur = conn.cursor()
        
        try:
            if work_id:
                cur.execute("""
                    SELECT id, title, work_type, subject, description, composition, 
                           price_points, rating, downloads, created_at, yandex_disk_link
                    FROM t_p63326274_course_download_plat.works WHERE id = %s
                """, (work_id,))
                row = cur.fetchone()
                
                if not row:
                    return {
                        'statusCode': 404,
                        'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                        'body': json.dumps({'error': 'Work not found'})
                    }
                
                work = {
                    'id': row[0],
                    'title': row[1],
                    'work_type': row[2],
                    'subject': row[3],
                    'description': row[4],
                    'composition': row[5],
                    'price_points': row[6],
                    'rating': float(row[7]) if row[7] else 0,
                    'downloads': row[8],
                    'created_at': row[9].isoformat() if row[9] else None,
                    'yandex_disk_link': row[10]
                }
                
                cur.execute("""
                    SELECT file_url, file_type, display_order
                    FROM t_p63326274_course_download_plat.work_files WHERE work_id = %s ORDER BY display_order
                """, (work_id,))
                
                work['files'] = [
                    {'url': f[0], 'type': f[1], 'order': f[2]}
                    for f in cur.fetchall()
                ]
                
                return {
                    'statusCode': 200,
                    'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                    'body': json.dumps(work)
                }
            else:
                cur.execute("""
                    SELECT id, title, work_type, subject, description, 
                           price_points, rating, downloads
                    FROM t_p63326274_course_download_plat.works ORDER BY created_at DESC
                """)
                
                works = []
                for row in cur.fetchall():
                    work = {
                        'id': row[0],
                        'title': row[1],
                        'work_type': row[2],
                        'subject': row[3],
                        'preview': row[4][:150] + '...' if len(row[4]) > 150 else row[4],
                        'price': row[5],
                        'rating': float(row[6]) if row[6] else 0,
                        'downloads': row[7]
                    }
                    works.append(work)
                
                return {
                    'statusCode': 200,
                    'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                    'body': json.dumps({'works': works})
                }
        finally:
            cur.close()
            conn.close()
    
    if method == 'POST':
        admin_email = event.get('headers', {}).get('x-admin-email') or event.get('headers', {}).get('X-Admin-Email')
        
        if admin_email != 'rekrutiw@yandex.ru':
            return {
                'statusCode': 403,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'error': 'Unauthorized'})
            }
        
        body_data = json.loads(event.get('body', '{}'))
        action = body_data.get('action')
        
        if action == 'remove_duplicates':
            conn = get_db_connection()
            cur = conn.cursor()
            
            try:
                # –ù–∞–π—Ç–∏ –∏ —É–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã, –æ—Å—Ç–∞–≤–∏–≤ —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ —Ä–∞–Ω–Ω–∏–µ –∑–∞–ø–∏—Å–∏
                cur.execute("""
                    DELETE FROM t_p63326274_course_download_plat.works
                    WHERE id NOT IN (
                        SELECT MIN(id)
                        FROM t_p63326274_course_download_plat.works
                        GROUP BY title
                    )
                """)
                deleted_count = cur.rowcount
                conn.commit()
                
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {deleted_count}")
                
                return {
                    'statusCode': 200,
                    'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                    'body': json.dumps({
                        'success': True,
                        'deleted': deleted_count,
                        'message': f'–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {deleted_count}'
                    })
                }
            finally:
                cur.close()
                conn.close()
        
        if action == 'import':
            public_key = body_data.get('public_key')
            offset = body_data.get('offset', 0)
            limit = body_data.get('limit', 50)
            
            if not public_key:
                return {
                    'statusCode': 400,
                    'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                    'body': json.dumps({'error': 'public_key required'})
                }
            
            folders = get_yandex_disk_folders(public_key)
            total_folders = len(folders)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º offset –∏ limit
            folders_batch = folders[offset:offset+limit]
            
            imported = []
            errors = []
            
            conn = get_db_connection()
            cur = conn.cursor()
            
            print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –∏–º–ø–æ—Ä—Ç –±–∞—Ç—á–∞ {offset}-{offset+len(folders_batch)} –∏–∑ {total_folders} —Ä–∞–±–æ—Ç...")
            
            try:
                for folder in folders_batch:
                    folder_name = folder['name']
                    yandex_disk_link = folder.get('public_url', '')
                    
                    parsed = parse_work_title_and_type(folder_name)
                    title = parsed['title']
                    work_type = parsed['work_type']
                    
                    subject = '–æ–±—â–∏–π'
                    description = f'–†–∞–±–æ—Ç–∞ –ø–æ —Ç–µ–º–µ: {title}. –¢–∏–ø —Ä–∞–±–æ—Ç—ã: {work_type}.'
                    composition = '–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ —Ñ–∞–π–ª—ã'
                    price_points = 150
                    
                    try:
                        # Escape single quotes for SQL
                        safe_title = title.replace("'", "''")
                        safe_work_type = work_type.replace("'", "''")
                        safe_subject = subject.replace("'", "''")
                        safe_desc = description.replace("'", "''")
                        safe_comp = composition.replace("'", "''")
                        safe_link = yandex_disk_link.replace("'", "''")
                        
                        cur.execute(f"""
                            INSERT INTO t_p63326274_course_download_plat.works (title, work_type, subject, description, composition, price_points, yandex_disk_link)
                            VALUES ('{safe_title}', '{safe_work_type}', '{safe_subject}', '{safe_desc}', '{safe_comp}', {price_points}, '{safe_link}')
                            RETURNING id
                        """)
                        
                        work_id = cur.fetchone()[0]
                        conn.commit()
                        
                        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ —Ä–∞–±–æ—Ç–∞ ID={work_id}: {title}")
                        
                        imported.append({
                            'filename': folder_name,
                            'work_id': work_id,
                            'title': title
                        })
                        
                    except Exception as e:
                        errors.append({
                            'filename': folder_name,
                            'error': str(e)
                        })
                        conn.rollback()
                
                return {
                    'statusCode': 200,
                    'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                    'body': json.dumps({
                        'success': True,
                        'imported': len(imported),
                        'errors': len(errors),
                        'total': total_folders,
                        'offset': offset,
                        'limit': limit,
                        'has_more': offset + limit < total_folders,
                        'next_offset': offset + limit if offset + limit < total_folders else None,
                        'details': {
                            'imported': imported,
                            'errors': errors
                        }
                    })
                }
            finally:
                cur.close()
                conn.close()
        
        title = body_data.get('title')
        work_type = body_data.get('work_type')
        subject = body_data.get('subject')
        description = body_data.get('description')
        composition = body_data.get('composition')
        price_points = body_data.get('price_points', 100)
        
        if not all([title, work_type, subject]):
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'error': 'Missing required fields'})
            }
        
        conn = get_db_connection()
        cur = conn.cursor()
        
        try:
            cur.execute("""
                INSERT INTO works (title, work_type, subject, description, composition, price_points)
                VALUES (%s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (title, work_type, subject, description, composition, price_points))
            
            work_id = cur.fetchone()[0]
            conn.commit()
            
            return {
                'statusCode': 201,
                'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'id': work_id, 'message': 'Work created'})
            }
        finally:
            cur.close()
            conn.close()
    
    return {
        'statusCode': 405,
        'headers': {'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*'},
        'body': json.dumps({'error': 'Method not allowed'})
    }